# Detection of Recolored Images using a Deep Discriminative Model

  Image recoloring is a technique that can transfer image color or theme and result in an imperceptible change in human eyes. Although image recoloring is one of the most important image manipulation techniques, there is no special method designed for detecting this kind of forgery. In this project, we propose a trainable end-to-end system for distinguishing recolored images from natural images. The proposed network takes the original image and two derived inputs based on illumination consistency and inter-channel correlation of the original input into consideration and outputs the probability that it is recolored. Our algorithm adopts a CNN-based deep architecture, which consists of three feature extraction blocks and a feature fusion module. To train the deep neural network, we synthesize a dataset comprised of recolored images and corresponding ground truth using different recoloring methods. Extensive experimental results on the recolored images generated by various methods show that our proposed network is well generalized and much robust.


  In the system we are proposing to implement, we use three feature extractors and a feature fusion module to learn forgery-relevant features. The We adopt the original image as one of the input branches like traditional neural networks. Additionally, we derive DI(Difference Image)s and IM(Illumination Module) as two pieces of evidence of image recolored detection based on the observations that images may not maintain the inter-channel correlation or illuminant consistency after the recoloring process. These two pieces of evidence are employed as two additional input branches together with the original image. Since the learned features are based on a data-driven approach, they are able to describe the intrinsic properties of forgery formation and help distinguishing the authenticity of an image. After extracting forgery-relevant features, we use a feature fusion network to refine these features and output the probability of authenticity. Based on this premise, we evaluate the proposed algorithm on forged images generated by various color transfer methods and the images collected through the Internet.
  
## Table of contents

- [Installation](#installation)
    - [Prerequisites](#prerequisites)
    - [Technologies Used](#technologies-used)
- [System Modules](#modules)
    - [Training the System](#training)
        - [Collection of picture Data](#data-collection)
        - [Picture information extraction](#extraction)
        - [Concatenation & Fusion](#confus)
    - [Testing the System](#testing)
- [Developers](#developers)
- [Links](#links)
- [References](#references)
    
    
## Installation <a name='installation'></a>

### Prerequisites <a name='prerequisites'></a>

1. Python 3 Environment (Ancaonda preferred)
2. Python modules required:NumPy,Pandas,Opencv2,Matplotlib, Scikit-learn, Keras
3. Web Browser

### Technologies Used <a name='technologies-used'></a>

1. Anaconda Jupyter Notebook



## System Modules <a name='model'></a>

> ### Training the System <a name='training'></a>

#### Collection of picture Data <a name='data-collection'></a>
- The training set is an essential component of the network. We use the VOC PASCAL  dataset which contains  images including both indoor and outdoor photographs. Since edit propagation and palette based recoloring methods require artiﬁcial manipulation and are inappropriate for generating a large number of training data, we only use the example-based recoloring methods to generate training data.
- As our recoloring detection is a binary classiﬁcation task, we need a balance between the positive and negative examples in training data. In this work, given an original photograph I, we randomly select one recoloring method to generate the recolored image. Therefore, the ratio between the positive and negative examples is 1, which is the most appropriate for binary classiﬁcation using the neural network.


#### Picture information extraction <a name='extraction'></a>
- Here we extract the features of each input. In this section, we analyze the relations between recoloring performance and factors like different input branches and illuminant estimation algorithms.
- We take DI(Difference Image)s and IM(Illumination Module) as two pieces of evidence of image recolored detection based on the observations that images may not maintain the inter-channel correlation or illuminant consistency after the recoloring process. These two pieces of evidence are employed as two additional input branches together with the original image.


#### Concatenation & Fusion <a name='confus'></a>

- In this step, we concatenate features of three inputs at different layers of the color and perform the comparison of the factor of comparison between each layer by using Illumination estimation algorithms
- We perform the comparison for more number of layers and color shades to improve the accuracy of the system.
- This step is performed multiple times until the comparison factor is steady or unchanged for two consecutive iterations.


> ### Testing the System <a name='testing'></a>

- Since color transferring methods have been widely used in human society, we further collect a new dataset that contains 80 recolored photos which are performed manually. Some of the photographs are produced by mobile APPs while others are downloaded from the websites such as Photoshop tutorial websites. All the downloaded images are mentioned that they are recolored. Some examples randomly selected from our dataset.
- Now the dataset is subjected to the trained system to check the accuracy of the system.



## Developer <a name='developers'></a>
* Kamal Yeshodhar Shastry Gattu

## Links <a name='links'></a>

GitHub:     [G K Y SHASTRY](https://github.com/kysgattu)

Contact me:     <gkyshastry0502@gmail.com>

## References <a name='references'></a>
[[1] Yanyang Yan, Wenqi Ren, Xiaochun Cao, “Recolored Image Detection via a Deep Discriminative Model,” IEEE Transactions On Information Forensics And Security, Vol. XX, No. X, July 2017
](https://ieeexplore.ieee.org/document/8355817)
